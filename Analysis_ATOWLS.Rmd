#Analysis Code for Atlantic NOS

ObservationCount1 = 1st minute + 2nd minute (i.e., silent listening period). 

Cleaning script for these data can be found at DMEthier/National-NOS

Code to read and append the relevant files from the out directory. This is ObservationCount1 for the national trends. 
```{r pull multiple files, echo=FALSE, message=FALSE}

#Read file that was created in ArcGIS. 
grid<-read.csv("ATOWL_test_dat.csv")

#Read in the events data then filer for just ATOWLS 
require(plyr)

out.dir<-"output/2019"
my.files<-list.files(path = out.dir, patter ="*ObservationCount1.csv", full.name=TRUE)
obs<-ldply(my.files, read.csv)

my.files<-list.files(path = out.dir, patter ="*EventData.csv", full.name=TRUE)
event.data<-ldply(my.files, read.csv)

#write out full events for plotting in ArcGIS
write.csv(event.data, paste(out.dir, "FullEventData.csv", sep=""))

event.data<-event.data %>% filter (StateProvince %in% c("NB", "NS", "PE")) %>% droplevels()
write.csv(event.data, paste(out.dir, "ATOWLS.FullEventData.csv", sep=""))

obs<-obs %>% filter (StateProvince %in% c("NB", "NS", "PE")) %>% droplevels()

#join grid to event so that we have the needed cell id for the analysis
event.data<-full_join(event.data, grid, by=c("RouteIdentifier", "survey_year", "CollectorNumber"))

detach(package:plyr) #detach or this will cause an issue with dplyr

```

Create summary stats
```{r sumstat, echo=FALSE, message=FALSE}

#Filter out non taret species. 
obs <- obs %>% filter (CommonName %in% c("Barred Owl", "Boreal Owl", "Great Gray Owl", "Great Horned Owl", "Northern Saw-whet Owl", "Eastern Screeh-Owl", "Western Screech-Owl", "Long-eared Owl", "Short-eared Owl", "Northern Hawk Owl", "Northern Pygmy-Owl", "Snowy Owl", "Barn Owl", "Flammulated Owl"))

#species by protocol summary. Check for missclassifications
sp.prot<-obs %>% select(CommonName, collection, ProtocolCode, StateProvince) %>% distinct()
sp.prot$count<-"x"
sp.prot<-cast(sp.prot, collection +StateProvince+ ProtocolCode~CommonName, value="count")

```

```{r anal.dat, echo = TRUE, message = FALSE}

#select desired data columns for analysis
obs<-obs %>% select("CommonName", "species_id", "RouteIdentifier", "SiteCode", "collection", "ProtocolCode", "survey_year", "CollectorNumber", "ObservationCount1")

```

We are ready to develope the species-specific analysis loop

```{r sp.loop, echo = TRUE, message = FALSE}

## Generate species list for analysis. The speices that make the cut will vary on province based on the data manipulation
species.list <- unique(obs$CommonName)

for(m in 1:length(species.list)) {

m<-1 #for testing each species
   
  sp.data <-NULL 
  sp.data <- filter(obs, CommonName == species.list[m]) %>%
      droplevels()
  
  print(paste("Currently analyzing species ", m, "/", species.list[m], sep = "")) 

#zero fill by merging with the events dataframe. 
sp.data <- left_join(event.data, sp.data, by = c("RouteIdentifier", "survey_year", "CollectorNumber")) %>% mutate(ObservationCount1 = replace(ObservationCount1, is.na(ObservationCount1), 0))

# Limit to species observed at least once per route 
# summarize survey site to determine which species have been observed at least once (looking at the total count column) those with sum <= 1 across all survey years will be dropped from analysis (implies never observed on a route (i.e., outside range or inappropraite habitat))

  site.summ <- melt(sp.data, id.var = "RouteIdentifier",	measure.var = "ObservationCount1")
  site.summ <- cast(site.summ, RouteIdentifier ~ variable,	fun.aggregate="sum")
  site.sp.list <- unique(subset(site.summ, select = c("RouteIdentifier"), ObservationCount1 >= 1))
  
# limit raw data to these species, i.e., those that were observed at least once on a route 
  sp.data <- merge(sp.data, site.sp.list, by = c("RouteIdentifier"))

#count the number of owls per route as the response varaible. The number of stop on a route is being included as a covarite in the model to control for route level effort
sp.data<-sp.data %>% group_by(RouteIdentifier, survey_year, CollectorNumber, grid_id, nstop, StateProvince, bcr, latitude, longitude) %>% summarise(count1=sum(ObservationCount1))
 
#create the offset variable which is the number of routes run in a year to control for changes in effor over time. Previously I was using the log transformed nroute as an offset (E), however, this assumes that doubling the number of routes will double the number of owls counted, which may not hold true. The other option is to add nroute as a covariate in the model (Zuur 2018 pg 445). 

#the spatailly expict apprach pools counts across geographic statum and deals with the issue of count circles becoming active or inactive over time, thus temporal variability in route level effort. 

#nroute<-NULL
#nroute<-sp.data%>% group_by(survey_year) %>% summarise(nroute=n_distinct(RouteIdentifier))
#sp.data<-left_join(nroute, sp.data, by="survey_year")

#create a first-year observer effect varaible 
library(plyr)
obseff<-NULL #clear previous
obseff<- ddply(sp.data,~CollectorNumber,function(d)d[which.min(d$survey_year),]) 
obseff$ObsEffect<-1
obseff<-obseff %>% select(RouteIdentifier, survey_year, CollectorNumber, ObsEffect)

#detach plyr once finished with it because it has a tendancy to mess up the dplyr packages  
detach(package:plyr)
library(dplyr) #sometime this will need reinstalled here(?)

#create a route-observer effect
sp.data$routeobs <- paste0(sp.data$RouteIdentifier, "-", sp.data$CollectorNumber)

sp.data<-left_join(sp.data, obseff, by=c("RouteIdentifier", "survey_year", "CollectorNumber"))
sp.data<-sp.data %>% mutate(ObsEffect = replace(ObsEffect, is.na(ObsEffect), 0)) 
 
#standardize year to 2019   
sp.data <- sp.data %>% mutate(std_yr = survey_year - max.yr)

#Get grid data for plotting
ATOWLS_Point <- readOGR(dsn="C:/Users/dethier/Documents/ethier-scripts/National-NOS/Data", layer="ATOWLS_Point") # epsg 102005
head(ATOWLS_Point@data)

ATOWLS_Grid <- readOGR(dsn="C:/Users/dethier/Documents/ethier-scripts/National-NOS/Data", layer="ATOWLS_Grid")
names(ATOWLS_Grid)[1] <- "grid_id"; head(ATOWLS_Grid@data)

nos_na_grid <- readOGR(dsn="C:/Users/dethier/Documents/ethier-scripts/National-NOS/Data", layer="nos_na_grid")
nos_na_grid$na_id <- nos_na_grid$id; head(nos_na_grid@data)

plot(nos_na_grid)
plot(ATOWLS_Grid, col="red", add=T)
grid1 <- as(ATOWLS_Grid, "sf")
#plot(ATOWLS_Point, col="blue", add=T) #this did not work correctly due to an issue with projection
grid_key <- unique(sp.data[, c("grid_id", "bcr")])
row.names(grid_key) <- NULL

# summarize routes per grid ----------------------------------
# how many routes per occupied grid cell
names(sp.data)
route_per_cell <- sp.data %>%
  dplyr::select(RouteIdentifier, grid_id, longitude, latitude) %>%
  arrange(grid_id) %>% unique() %>%
  mutate(occupied=ifelse(is.na(longitude), 0, 1)) %>% #already removed routes without the species
  group_by(grid_id) %>%
  summarise(number_routes=sum(occupied))
ggplot(route_per_cell, aes(number_routes)) +
  geom_histogram(breaks=c(0:20), fill="gray60", color="white") +
  xlab("Number of routes per grid cell") + ylab("Count")
summary(route_per_cell)

##-----------------------------------------------------------



## make neighbors
nb1 <- poly2nb(ATOWLS_Grid, row.names=ATOWLS_Grid$grid_id); nb1

#Neighbour list object:
#Number of regions: 25 
#Number of nonzero links: 140 
#Percentage nonzero weights: 22.4 
#Average number of links: 5.6 

is.symmetric.nb(nb1, verbose = FALSE, force = TRUE)
nb2INLA("nb1.graph", nb1)
nb1.adj <- paste(getwd(),"/nb1.graph", sep="")
g1 <- inla.read.graph("nb1.graph")
plot(nb1, coordinates(ATOWLS_Grid), col="red", cex=0.5)

# index 
# where i = grid cell, k = route, t = year
sp.data$eps_i <- sp.data$alpha_i <- as.integer(factor(sp.data$grid_id))
sp.data$omega_i<-sp.data$tau_i <- sp.data$eps_i
sp.data$kappa_k <- as.integer(factor(sp.data$routeobs))
sp.data <- arrange(sp.data, grid_id, std_yr)
n_routeobs <- max(sp.data$kappa_k, na.rm=T)
n_cells <- max(sp.data$alpha_i, na.rm=T)

# specify model with year cell effects so that we can predict the annual index value for each cell
# rather then using the cell ID use the factor assigned previously to alpha_i
sp.data$gamma_ij <- paste0(sp.data$alpha_i, "-", sp.data$survey_year)

# make and run model 

form1 <- count1 ~ -1 + # remove grand mean
  # cell ICAR random intercepts
  f(alpha_i, model="besag", graph=g1, constr=FALSE, scale.model=TRUE,
    hyper = list(prec = list(prior = "pc.prec", param = c(1, 0.01)))) +
  # cell ICAR random effort slopes for nstops 
  f(eps_i, nstop, model="besag", graph=g1, constr=FALSE, scale.model=TRUE,
    hyper = list(prec = list(prior = "pc.prec", param = c(1, 0.01)))) +
  # cell ICAR random year slopes
  f(tau_i, std_yr, model="besag", graph=g1, constr=FALSE, scale.model=TRUE,
    hyper = list(prec = list(prior = "pc.prec", param = c(1, 0.01)))) +
  # random route-observer intercepts
  f(kappa_k, model="iid", constr=TRUE,
    hyper = list(prec = list(prior = "pc.prec", param = c(1, 0.01)))) +
 # cell-year effect
  f(gamma_ij, model="iid", constr=TRUE, 
   hyper = list(prec = list(prior = "pc.prec", param = c(1, 0.01))))

# get results
out1<- inla(form1, family="nbinomial", data=sp.data,
            control.compute=list(cpo=T, config=T),
            control.inla=list(strategy="adaptive",
                              int.strategy="auto"),
            num.threads=3,
            verbose=T)

# view summaries
summary(out1, digits=3)

## remove cells with no routes
## have not implemented this in this particular example
cells_with_counts <- unique(sp.data$alpha_i[which(!is.na(sp.data$count1))])

# get alpha summaries
alph <- exp(out1$summary.random$alpha_i$`0.5quant`[cells_with_counts])
alph_ll <- exp(out1$summary.random$alpha_i$`0.025quant`[cells_with_counts])
alph_ul <- exp(out1$summary.random$alpha_i$`0.975quant`[cells_with_counts])
alph_iw <- alph_ul - alph_ll
hist(alph); summary(alph)
hist(alph_ll); summary(alph_ll)
hist(alph_ul); summary(alph_ul)

# get epsilon summaries
eps <- out1$summary.random$eps_i$`0.5quant`[cells_with_counts]
eps_ll <- out1$summary.random$eps_i$`0.025quant`[cells_with_counts]
eps_ul <- out1$summary.random$eps_i$`0.975quant`[cells_with_counts]
eps_iw <- eps_ul - eps_ll
hist(eps); summary(eps); round(sum(eps<1)/length(eps), 2)
hist(eps_ll); summary(eps_ll)
hist(eps_ul); summary(eps_ul)
round(sum(eps_ll<=1 & eps_ul>=1)/length(eps_ll), 2)
round(sum(eps_ll<=0 & eps_ul>=0)/length(eps_ll), 2)
cor.test(eps, alph, method="spearman")

# get tau summaries
tau <- (exp(out1$summary.random$tau_i$`0.5quant`[cells_with_counts])
        - 1) * 100
tau_ll <- (exp(out1$summary.random$tau_i$`0.025quant`[cells_with_counts])
           - 1) * 100
tau_ul <- (exp(out1$summary.random$tau_i$`0.975quant`[cells_with_counts])
           - 1) * 100
tau_iw <- tau_ul - tau_ll
hist(tau); summary(tau); round(sum(tau>=0)/length(tau), 2)
hist(tau_ll); summary(tau_ll)
hist(tau_ul); summary(tau_ul)
hist(tau_iw); summary(tau_iw)
round(sum(tau_ll<=0 & tau_ul<=0)/length(tau_ll), 2)
round(sum(tau_ll>=0 & tau_ul>=0)/length(tau_ll), 2)
cor.test(alph, tau, method="spearman")

# gof
sum(out1$cpo$failure, na.rm=T)
-2 * sum(log(out1$cpo$cpo[out1$cpo$failure==0]), na.rm=T)
pit1 <- data.frame(PIT=out1$cpo$pit) %>%
  filter(out1$cpo$pit<0.99 & out1$cpo$failure!=1 & out1$cpo$pit>0.01)
pit2 <- ggplot(data=pit1, aes(x=PIT)) +
  geom_histogram(col="white") +
  xlab("Probability integral transform (PIT)") +
  ylab("Count"); pit2; summary(pit1$PIT)
# ------------------------------------------------------------------------------

#time series plots per cell
#calcualte cell level index of abundance
 cell_ts <- function(cell1=1){
   d0 <- out1$summary.random$alpha_i$`0.5quant`[cell1]
   d1 <- out1$summary.random$tau_i$`0.5quant`[cell1]
   d2 <- data.frame(
   year=as.numeric(gsub(paste0(cell1,"-"), "",
                        grep(paste0("\\b",cell1,"-"),
                             out1$summary.random$gamma_ij$ID,
                                  value=TRUE)))- max.yr,
   gamma_ij=
     out1$summary.random$gamma_ij$`0.5quant`[grep(
       paste0("\\b",cell1,"-"), out1$summary.random$gamma_ij$ID)]) %>%
     arrange(year)
   d2$x0 <- d0
   d2$x1 <- d2$year*d1
   d2$abund <- exp(d2$x0 + d2$x1 + d2$gamma_ij)
   d2$trend <- exp(d2$x0 + d2$x1)
   ggplot(d2, aes(x=year+2019)) + geom_line(aes(y=trend)) +
   geom_point(aes(y=abund)) 
   #+ label=paste0("Grid cell number ", cell1)
 }
 
#to plot a subset of the cell specific trends and indicies 
 cell2 <- c(1,2,3,4,5)
 for(i in cell2){
   print(cell_ts(i))
 }

 # explore posterior samples -----------------------------------------------------------------------------
posterior_ss <- 10 # change as appropriate
samp1 <- inla.posterior.sample(posterior_ss, out1, num.threads=3)
par_names <- as.character(attr(samp1[[1]]$latent, "dimnames")[[1]])
post1 <- as.data.frame(sapply(samp1, function(x) x$latent))
post1$par_names <- par_names
 
 
 # tau samples
tau_samps1 <- post1[grep("tau_i", post1$par_names), ]
row.names(tau_samps1) <- NULL
tau_samps1 <- tau_samps1[cells_with_counts, 1:posterior_ss]
tau_samps1 <- (exp(tau_samps1) - 1) * 100
tau_samps2 <- cbind(grid_key[cells_with_counts,], tau_samps1)
row.names(tau_samps2) <- NULL
val_names <- grep("V", names(tau_samps2))

# tau_bcr
tau_bcr <- tau_samps2 %>%
  dplyr::select(bcr, val_names) %>%
  mutate(bcr=factor(bcr)) %>%
  gather(key=key, val=val, -bcr) %>%
  dplyr::select(-key) %>%
  group_by(bcr) %>%
  summarise(med_tau=median(val), lcl_tau=quantile(val, probs=0.025),
            ucl_tau=quantile(val, probs=0.975), iw_tau=ucl_tau-lcl_tau,
            n=n()/posterior_ss); head(tau_bcr)

# tau_total
tau_tot <- tau_samps2 %>%
  dplyr::select(val_names) %>%
  as.matrix() %>%
  as.numeric() %>%
  quantile(probs=c(0.5, 0.025, 0.975)); tau_tot


# collect posterior summaries into one dataframe -------------------------------
post_sum<-NULL
post_sum <- data.frame(grid_id=cells_with_counts,
                       alph, alph_ll, alph_ul, alph_iw,
                       eps, eps_ll, eps_ul, eps_iw, eps_sig=NA,
                       tau, tau_ll, tau_ul, tau_iw, tau_sig=NA)
post_sum$eps_sig <- ifelse((post_sum$eps_ll < 1 & post_sum$eps_ul > 1),
                           post_sum$eps_sig <- NA,
                           post_sum$eps_sig <- post_sum$eps)
post_sum$tau_sig <- ifelse((post_sum$tau_ll < 1 & post_sum$tau_ul > 1),
                           post_sum$tau_sig <- NA,
                           post_sum$tau_sig <- post_sum$tau)
post_sum$bcr <- grid_key$bcr[cells_with_counts]
#post_sum$state <- grid_key$state[cells_with_counts]
#post_sum$country <- grid_key$country[cells_with_counts]
summary(post_sum)

#need to back assign the factor grid_id to its original value
id_grid<-sp.data %>% select(grid_id, alpha_i)
names(id_grid)[names(id_grid)=="alpha_i"] <- "id"
names(post_sum)[names(post_sum)=="grid_id"]<-"id"
post_sum<-merge(post_sum, id_grid, by="id")
post_sum$grid_id<-as.character(post_sum$grid_id)

# make cell level maps ---------------------------------------------------------
bcr_map <- readOGR(dsn="C:/Users/dethier/Documents/ethier-scripts/National-NOS/Data", layer="simple_bcr")
bcr_sf <- as(bcr_map, "sf")
post_sum<-distinct(post_sum) #need to take distinct rows
ATOWLS_Grid@data <- data.frame(ATOWLS_Grid@data, post_sum[match(ATOWLS_Grid@data[,"grid_id"], post_sum[,"grid_id"]),])
res_sf<-as(ATOWLS_Grid, "sf")
#results_cells <- merge(ATOWLS_Grid, post_sum, by="grid_id", all=F)
#res_sf <- as(results_cells, "sf")
plot(res_sf["tau"])
#ATOWLS_Grid <- ATOWLS_Grid[cells_with_counts, ]
#plot(ATOWLS_Grid)
#will want to fix this so I can plot routes too
#plot(cbc_amro_circles, add=T, pch=16, cex=0.5)

# map tau
tau_p1 <- ggplot() +
  geom_sf(data=bcr_sf, fill="gray40", col="gray40") +
  geom_sf(data=res_sf, aes(fill=tau), col="gray40", size=0.3) +
  scale_fill_gradient2("D. Tau\n(% per year)", low = ("royalblue4"),
                       mid = "white",
                       high = ("red4"), midpoint = 0, space = "Lab",
                       na.value = "grey40", guide = "colourbar") +
  theme_map() + theme(panel.grid.major=element_line(colour="transparent"))
tau_p2 <- ggplot() +
  geom_sf(data=bcr_sf, fill="gray40", col="gray40") +
  geom_sf(data=res_sf, aes(fill=tau_iw), col="gray40", size=0.3) +
  scale_fill_gradient2("F. Tau\ncredible\ninterval\nwidth\n(% per year)",
                       low = ("purple4"), mid = "white",
                       high = ("green4"), midpoint = 6, space = "Lab",
                       na.value = "grey40", guide = "colourbar",
                       breaks=c(3,6,9,12)) +
  theme_map() + theme(panel.grid.major=element_line(colour="transparent"))
tau_p3 <- ggplot() +
  geom_sf(data=bcr_sf, fill="gray40", col="gray40") +
  geom_sf(data=res_sf, aes(fill=tau_sig), col="gray40", size=0.3) +
  scale_fill_gradient2("E. Significant\ntau (% per year)",
                       low = muted("royalblue4"), mid = "gray95",
                       high = muted("red4"), midpoint = 0, space = "Lab",
                       na.value = "grey40", guide = "colourbar") +
  theme_map() + theme(panel.grid.major=element_line(colour="transparent"))
 multiplot(tau_p1, tau_p3, tau_p2, cols=2)
 
 
# aggregate results ------------------------------------------------------------
# summarise at bcr
new_bcr <- post_sum %>% group_by(bcr) %>%
  summarise(new_med_tau=median(tau), new_med_prec=median(tau_iw),
            new_min_prec=min(tau_iw), new_max_prec=max(tau_iw))





} #end species loop
```